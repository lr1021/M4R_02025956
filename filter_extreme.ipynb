{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "random.seed(42)\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = 0\n",
    "input_folder = f\"6_all_data_table/zone_{zone}\"\n",
    "\n",
    "# Files per category\n",
    "categories = [3, 4, 5]\n",
    "category_c_files = {key:[] for key in categories}\n",
    "for filename in os.listdir(input_folder):\n",
    "    category = int(filename[1])\n",
    "    category_c_files[category].append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile measure used: w10\n"
     ]
    }
   ],
   "source": [
    "columns = ['valid_time', 'time_step', 'latitude', 'latitude_rank',\n",
    "              'longitude', 'longitude_rank', 'coord_index', 'u10', 'u100', 'v10', 'v100',\n",
    "              'w10', 'w100', 'tp', 't2m', 'lsm', 'sp', 'tcw', 'e']\n",
    "\n",
    "quantile_measure = 'w10'\n",
    "print(f\"Quantile measure used: {quantile_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reservoir_sample_L_from_files(file_list, column, k, verbose=False):\n",
    "    \"\"\"\n",
    "    Implements Algorithm L for reservoir sampling across multiple files.\n",
    "    \n",
    "    :param file_list: List of file paths to process\n",
    "    :param column: Name of the column to sample from\n",
    "    :param k: Number of samples to retain\n",
    "    :return: List containing the final k samples\n",
    "    \"\"\"\n",
    "    reservoir = []  # Reservoir to store the selected sample\n",
    "    total_count = 0  # Tracks how many items have been seen\n",
    "    total_count_at_file_end = -1\n",
    "    next_file_count = 0\n",
    "    go_to_next = 0\n",
    "\n",
    "    W = math.exp(math.log(random.random()) / k) \n",
    "    # Maximum of k uniform values in [0, 1] (first skipping weight)\n",
    "\n",
    "    for file in file_list:\n",
    "        if verbose:\n",
    "            print(f\"Processing file: {file}\")\n",
    "        df = pd.read_csv(file, usecols=[column])  # Read only the necessary column\n",
    "        current_file_length = len(df)\n",
    "        total_count_at_file_start = total_count_at_file_end + 1\n",
    "        total_count_at_file_end = total_count_at_file_start + current_file_length - 1\n",
    "\n",
    "        # First k values\n",
    "        while len(reservoir) < k:\n",
    "            if total_count <= total_count_at_file_end:\n",
    "                reservoir.append(df[column][total_count - total_count_at_file_start])\n",
    "                total_count += 1\n",
    "            else:\n",
    "                next_file_count = total_count - total_count_at_file_end\n",
    "                go_to_next = 1\n",
    "                break\n",
    "        if go_to_next:\n",
    "            continue\n",
    "\n",
    "        if next_file_count:\n",
    "            if next_file_count<current_file_length:\n",
    "                reservoir[random.randint(0, k - 1)] = df[column][next_file_count-1]\n",
    "            else:\n",
    "                next_file_count = next_file_count - current_file_length\n",
    "                go_to_next = 1\n",
    "        if go_to_next:\n",
    "            continue\n",
    "\n",
    "        while True:\n",
    "            skip = math.floor(math.log(random.random()) / math.log(1 - W)) + 1\n",
    "            # Skip from geometric distribution with probability of success W\n",
    "            W *= math.exp(math.log(random.random()) / k)\n",
    "            # Maximum of k uniform values in [0, W] (next skipping weight)\n",
    "            next_count = total_count + skip\n",
    "            if next_count <= total_count_at_file_end:\n",
    "                total_count = next_count\n",
    "                reservoir[random.randint(0, k - 1)] = df[column][total_count - total_count_at_file_start]\n",
    "            else:\n",
    "                total_count = next_count\n",
    "                next_file_count = total_count - total_count_at_file_end\n",
    "                break\n",
    "\n",
    "    return reservoir  # Return the final sampled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 3 finished. Reservoir sample length 100000\n",
      "95% quantile 11.763\n",
      "Category 4 finished. Reservoir sample length 100000\n",
      "95% quantile 12.215\n",
      "Category 5 finished. Reservoir sample length 100000\n",
      "95% quantile 12.547\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "# Reservoir samples\n",
    "L_samples = {}\n",
    "for c in categories:\n",
    "    files = [os.path.join(input_folder, filename) for filename in category_c_files[c]]\n",
    "    L_samples[c] = reservoir_sample_L_from_files(files, 'w10', 100000)\n",
    "    print(f\"Category {c} finished. Reservoir sample length {len(L_samples[c])}\")\n",
    "    print(f\"95% quantile {np.quantile(np.array(L_samples[c]),0.95):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zone 0\n",
      "\n",
      " Category 3\n",
      "50.0% : 4.99\n",
      "80.0% : 7.77\n",
      "90.0% : 9.65\n",
      "95.0% : 11.76\n",
      "99.0% : 17.25\n",
      "99.5% : 19.49\n",
      "\n",
      " Category 4\n",
      "50.0% : 5.18\n",
      "80.0% : 8.30\n",
      "90.0% : 10.24\n",
      "95.0% : 12.22\n",
      "99.0% : 17.43\n",
      "99.5% : 19.87\n",
      "\n",
      " Category 5\n",
      "50.0% : 4.94\n",
      "80.0% : 7.87\n",
      "90.0% : 10.13\n",
      "95.0% : 12.55\n",
      "99.0% : 18.83\n",
      "99.5% : 21.50\n"
     ]
    }
   ],
   "source": [
    "# Find quantiles with reservoir sampling\n",
    "quantiles = [.50, .80, .90, .95, .95, .99, .995]\n",
    "category_c_quantiles = {}\n",
    "for c in categories:\n",
    "    sample = L_samples[c]\n",
    "    category_c_quantiles[c] = {q : np.quantile(sample, q) for q in quantiles}\n",
    "\n",
    "print(f\"Zone {zone}\")\n",
    "for c in categories:\n",
    "    print(f\"\\n Category {c}\")\n",
    "    q_c = category_c_quantiles[c]\n",
    "    for q, qv in q_c.items():\n",
    "        print(f\"{100*q:.1f}% : {qv:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 3 0.95 quantile value 11.76308688205934\n",
      "Finished processing category 3 \n",
      " Kept 887173 out of 17705988 rows (5.01) \n",
      "\n",
      "Category 4 0.95 quantile value 12.215182456939443\n",
      "Finished processing category 4 \n",
      " Kept 1980483 out of 39498228 rows (5.01) \n",
      "\n",
      "Category 5 0.95 quantile value 12.546528792597863\n",
      "Finished processing category 5 \n",
      " Kept 2395110 out of 47808828 rows (5.01) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "kept = 0\n",
    "quantile = 0.95\n",
    "quantile_str = \"(q\" + str(int(quantile*100)) + \")\"\n",
    "for c in categories:\n",
    "    quantile_val = np.quantile(np.array(L_samples[c]), quantile)\n",
    "    print(f\"Category {c} {quantile} quantile value {quantile_val}\")\n",
    "    files = [os.path.join(input_folder, filename) for filename in category_c_files[c]]\n",
    "    for filename in files:\n",
    "        new_name = \"8_filtered_data_table\" + filename[16:-4] + quantile_str + \".csv\"\n",
    "\n",
    "        # Find rows\n",
    "        df = pd.read_csv(filename, index_col=False)\n",
    "        total += len(df)\n",
    "        df = df.loc[df[quantile_measure]>=quantile_val,:]\n",
    "        kept += len(df)\n",
    "        df.to_csv(new_name, index=False)\n",
    "    print(f\"Finished processing category {c} \\n Kept {kept} out of {total} rows ({kept/total*100:.2f}) \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M4R_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
